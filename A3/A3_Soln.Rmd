---
title: "A3 Soln"
author: "Xiangyu Kong, 1002109620"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document: default
---

```{r setup, include=FALSE, message=FALSE}
# packages
library(glmmTMB)
library(gamm4)
library(knitr)
library(mgcv)
library(tidyverse)

# chunk options
knitr::opts_chunk$set(
  echo = FALSE,
  eval = FALSE,
  message = FALSE,
  tidy.opts = list(width.cutoff = 60)
)

# Set random seed
set.seed(9620)
```


# Question 1 Birth

``` {r 1. read data}
birth_file = 'birthData.rds' 
if (!file.exists(birth_file)) {
  download.file('http://pbrown.ca/teaching/303/data/birthData.rds',
                birth_file)
}
x = readRDS(birth_file)
```

``` {r 1. process data}
# a unique urban / hispanic indicator
x$bygroup = factor(gsub(
  "[[:space:]]",
  "",
  paste0(x$MetroNonmetro, x$MothersHispanicOrigin)
))
x$timeInt = as.numeric(x$time)
x$y = as.matrix(x[, c('Male', 'Female')])
x$sin12 = sin(x$timeInt / 365.25)
x$cos12 = cos(x$timeInt / 365.25)
x$sin6 = sin(2 * x$timeInt / 365.25)
x$cos6 = cos(2 * x$timeInt / 365.25)
baselineDate = as.Date('2007/1/1')
baselineDateInt = as.integer(baselineDate)
```

``` {r 1. gam}
res = mgcv::gam(
  y ~ bygroup +
    cos12 + sin12 + cos6 + sin6 +
    s(timeInt, by = bygroup, k = 120, pc = baselineDateInt),
  data = x,
  family = binomial(link = 'logit')
)
```

``` {r 1. gamm}
res2 = gamm4::gamm4(
  y ~ bygroup +
    cos12 + sin12 + cos6 + sin6 +
    s(timeInt, by = bygroup, k = 120, pc = baselineDateInt),
  random = ~ (1 | bygroup:timeInt),
  data = x,
  family = binomial(link = 'logit')
)
```

``` {r 1. coefs}
coefGamm = summary(res2$mer)$coef 

knitr::kable(cbind(mgcv::summary.gam(res)$p.table[, 1:2],
                   coefGamm[grep("^Xs[(]", rownames(coefGamm), invert = TRUE), 1:2]),
             digits =5)

1/sqrt(res$sp)

lme4::VarCorr(res2$mer)
```

``` {r 1. predict seasonally adjusted time trend}
timeJan = as.numeric(as.Date('2010/1/1')) / 365.25

toPredict = expand.grid(
  timeInt = as.numeric(seq(
    as.Date('2007/1/1'), as.Date('2018/12/1'), by = '1 day'
  )),
  bygroup = c('MetroHispanicorLatino', 'NonmetroNotHispanicorLatino'),
  cos12 = cos(timeJan),
  sin12 = sin(timeJan),
  cos6 = cos(timeJan / 2),
  sin6 = sin(timeJan / 2)
)

predictGam = mgcv::predict.gam(res, toPredict, se.fit = TRUE)
predictGamm = predict(res2$gam, toPredict, se.fit = TRUE)
```

``` {r 1. predict random effects}
ranef2 = lme4::ranef(res2$mer, condVar = TRUE, whichel = 'bygroup:timeInt')
ranef2a = exp(cbind(est = ranef2[[1]][[1]], 
                    se = sqrt(attributes(ranef2[[1]])$postVar))
              %*% Pmisc::ciMat())
```


\pagebreak
## Question 1.1

*Write down statistical models corresponding to res and res2*

**Answer:**

The statistical model for `res` is 

$$
\begin{aligned}
  Y_{i} &\sim Binomial(N_{i}, p_{i}) \\
  h(p_{i}) = log(\frac{p_{i}}{1 - p_{i}}) 
   & = X_{i} \beta + s(t_{i}) + f(W_{i}; v) + \epsilon_{i}
\end{aligned}
$$

Where

- $Y_{i}$ is the response variable. It represents the number of babies that are males for group $i$.
- $p_{i}$ is the proportion of male babies in group $i$.
- $N_{i}$ is the total number of babies in group $i$.
- $h(p_{i})$ is the logit link function.
- $X_{i}$, $W_{i}$ are the covariates.
  - $X_{i}$ contains indicator variable `bygroup` (combination of `MetroNonmetro` and `MothersHispanicOrigin`, 4 levels)
  - $W_{i}$ contains numeric variable `timeInt` (the date of birth represented in numeric), interacting with indicator variable `bygroup`.
- $\beta$ are the parameters.
- $f(w; v)$ are the smoothing functions of `timeInt` interacting with `bygroup`, with smoothness parameter $v$, up to $120$ knots.
- $t_{i}$ is the numeric variable `timeInt` in group $i$.
- $s(t_{i})$ is seasonal cycle function of `timeInt`. It represents two frequencies: 12-month ($sin(\pi t_{i} / 365.25)$, $cos(\pi t_{i}$) and a 6-month ($sin(2 \pi t_{i} / 365.25)$, $cos(2 \pi t_{i} / 365.25)$).
- $\epsilon_{i}$ are residuals for group $i$.


The statistical model for `res2` is 

$$
\begin{aligned}
  Y_{it} ~ | ~ U_{it} &\sim Binomial(p_{it}, N_{it}) \\
  h(p_{it}) = log(\frac{p_{it}}{1 - p_{it}}) 
   & = X_{it} \beta + U_{it} + s(t_{i}) + f(W_{it}; v) + \epsilon_{it} \\
  U_{it} &\sim N(0, \sigma_{U}^{2})
\end{aligned}
$$

Where

- $Y_{it}$ is the response variable. It represents the number of babies that are males for time $t$ in bygroup level $i$.
- $p_{it}$ is the proportion of male babies for time $t$ in bygroup level $i$.
- $N_{it}$ is the total number of babies for time $t$ in bygroup level $i$.
- $h(p_{it})$ is the logit link function.
- $X_{it}$, $W_{it}$ are the covariates.
  - $X_{it}$ contains indicator variable `bygroup` (combination of `MetroNonmetro` and `MothersHispanicOrigin`, 4 levels).
  - $W_{it}$ contains numeric variable `timeInt` (the date of birth represented in numeric), interacting with indicator variable `bygroup`.
- $\beta$ are the parameters.
- $U_{it}$ is the $i$th `bygroup` level's $t$th `timeInt`'s deviation from the population average.
- $f(w; v)$ are the smoothing functions of `timeInt` interacting with `bygroup`, with smoothness parameter $v$, up to $120$ knots.
- $t_{it}$ is the numeric variable `timeInt` for time $t$ in bygroup level $i$.
- $s(t_{ij})$ is seasonal cycle function of `timeInt`. It represents two frequencies: 12-month ($sin(\pi t_{ij} / 365.25)$, $cos(\pi t_{ij}$) and a 6-month ($sin(2 \pi t_{ij} / 365.25)$, $cos(2 \pi t_{ij} / 365.25)$).
- $\epsilon_{it}$ are residuals for group $it$.


\pagebreak
## Question 1.2

*Which of the two sets of results is more useful for investigating this research hypothesis?*

**Answer:**

<!-- res -->

<!-- The results for `res` is more useful for investigating the hypothesis that stress induced by Trump’s election is affecting the sex ratio at birth. -->

<!-- The different between `res` and `res2` is that `res` is smoothed with generalized cross validation, where as `res2` is smoothed with maximum likelihood, and contains a random effect of `timeInt` interacting with `bygroup`. -->

<!-- From Figure 2 we can see that the predicted time trends for `res` is more wiggly, indicating that the model explains short-term trend well. The predicted time trend for `res2` is smoother and straighter, indicating that the model is more suited for explaining long-term trend. The hypothesis focuses on a specific period of time (after Trump's election), so a short term model (`res`) will explain the trend better. -->

<!-- From Figure 3, we can see that the random effects for `res2` are very similar. Both the exponentiated effects are scattered around $1.00$ level, so the effects are almost $0$. This suggests that we potentially do not need the random effects. -->

<!-- Since we potentially do not need the random effects, and `res` explains the short-term effects better than `res2`, `res` is more suited to investicating this research hypothesis. -->

<!-- res2 -->
The results for `res2` is more useful for investigating the hypothesis that stress induced by Trump’s election is affecting the sex ratio at birth.

The difference between `res` and `res2` is that `res` is smoothed with generalized cross validation, where as `res2` is smoothed with maximum likelihood, and contains a random effect of `timeInt` interacting with `bygroup`.

From Figure 3, we can see that the random effects for `res2` are very similar. Both the exponentiated effects are scattered around $1.00$ level, so the effects are almost $0$. This suggests that we potentially do not need the random effects.

From Figure 2 we can see that the predicted time trends for `res` is more wiggly. The red fitted line for `NonmetroNotHispanicorLatino` fluctuates a great deal and does not provide a clear indication of the trend. The predicted time trend for `res2` is smoother and straighter, indicating that the model is more suited for explaining the trend. 

The hypothesis focuses on the trend before and after Trump's election. Although we potentially do not need the random effects, `res2` explains the trend better than `res`, so `res2` is more suited to investicating this research hypothesis.


\pagebreak
## Question 1.3

*Write a short report (a paragraph or two) addressing the following hypothesis: The long-term trend in sex ratios for urban Hispanics and rural Whites is consistent with the hypothesis that discrimination against Hispanics, while present in the full range of the dataset, has been increasing in severity over time.*

**Answer:**

Using the model selected from part 2, we look at results produced by `res2`.

By looking at the prediction graphs (Figure 2: Predicted time trends), the predictions for `res2` presents two smooth curves. From the graph, we see that rural Whites have a relatively flat curve while urban Hispanics has a downward trend. This indicates that over the timespan of 2007 to 2019, the ratio of male to female babies remains relatively the same for rural Whites, and the ratio of male to female babies decreases for urban Hispanic. The two lines diverge as time progress, meaning that the difference of male to female ratio between rural Whites and urban Hispanic increases over time. 

The $95\%$ confidence intervals only barely overlapp on the left side, and do not overlap for most of the time, indidcating that this increasing difference is significant.  

Combining the two satements that stress during pregnancy reduces the number of male babies, and racial discrimination increases stress, we can say that the increasing difference of male to female ratio between rural Whites and urban Hispanic (urban Hispanic having the lower ratio) suggests that the stress for urban Hispanic might be higher over time, and could further indicate that the discrimination against Hispanics has been increasing in severity over time.


\pagebreak
## Question 1.4

*Write a short report addressing the following hypothesis: The election of Trump in November 2016 had a noticeable effect on the sex ratio of Hispanic-Americans roughly 5 months after the election.*

**Answer:**

Using the model selected from part 2, we look at results produced by `res2`.

By looking at the prediction graphs (Figure 2: Predicted time trends), the predictions for `res2` presents two smooth curves. From the graph, we see that urban Hispanics has a downward trend. This indicates that over the timespan of 2007 to 2019, the ratio of male to female babies decreases for urban Hispanic. The line is relatively straight, meaning from 2007 to 2019, the rate of decreasing (coresponding to the slope of the graph) is constant.

If Trump's election had a noticable effect on the sex ratio of Hispanic-Americans, the rate of the decreasing of male to female ratio would be changed, resulting in a different slope and a more wiggly line after November 2016. However, this was not shown in the prediction graph. The straight line after November 2016 with constant slope suggests that Trump's election did not have a noticable effect on the sex ratio of Hispanic-Americans. Thus we can reject the hypothesis that the election of Trump in November 2016 had a noticeable effect on the sex ratio of Hispanic-Americans roughly 5 months after the election.


\pagebreak
# Question 2

``` {r 2. read data}
if(!requireNamespace("nCov2019")) {
  devtools::install_github("GuangchuangYu/nCov2019")
}

x1 <- nCov2019::load_nCov2019(lang = 'en')

hubei = x1$province[which(x1$province$province == 'Hubei'), ]
hubei$deaths = c(0, diff(hubei$cum_dead))

italy = x1$global[which(x1$global$country == 'Italy'), ]
italy$deaths = c(0, diff(italy$cum_dead))

x = list(Hubei = hubei, Italy = italy)
```

``` {r 2. plot}
for (D in names(x)) {
  plot(x[[D]][, c('time', 'deaths')], xlim = as.Date(c('2020/1/10', '2020/4/1')))
}
```

``` {r 2. process data}
x$Hubei$weekday = format(x$Hubei$time, '%a')
x$Italy$weekday = format(x$Italy$time, '%a')
x$Italy$timeInt = as.numeric(x$Italy$time)
x$Hubei$timeInt = as.numeric(x$Hubei$time)
x$Italy$timeIid = x$Italy$timeInt
x$Hubei$timeIid = x$Hubei$time
```

``` {r 2. gamm italy}
gamItaly = gamm4::gamm4(
  deaths ~ weekday + s(timeInt, k = 40),
  random = ~ (1 | timeIid),
  data = x$Italy,
  family = poisson(link = 'log')
)
```

``` {r 2. gamm hubei}
gamHubei = gamm4::gamm4(
  deaths ~ weekday + s(timeInt, k = 100),
  random = ~ (1 | timeIid),
  data = x$Hubei,
  family = poisson(link = 'log')
)
```

``` {r 2. gamm results}
lme4::VarCorr(gamItaly$mer)
lme4::VarCorr(gamHubei$mer)
knitr::kable(cbind(summary(gamItaly$mer)$coef[, 1:2],
                   summary(gamHubei$mer)$coef[, 1:2]),
             digits = 3)

toPredict = data.frame(time = seq(as.Date('2020/1/1'), as.Date('2020/4/10'),
                                  by = '1 day'))
toPredict$timeInt = as.numeric(toPredict$time)
toPredict$weekday = 'Fri'
Stime = pretty(toPredict$time)

matplot(
  toPredict$time,
  exp(do.call(
    cbind,
    mgcv::predict.gam(gamItaly$gam, toPredict, se.fit = TRUE)
  )
  %*% Pmisc::ciMat()),
  col = 'black',
  lty = c(1, 2, 2),
  type = 'l',
  xaxt = 'n',
  xlab = '',
  ylab = 'count',
  ylim = c(0.5, 5000),
  xlim = as.Date(c('2020/2/20', '2020/4/5'))
)
axis(1, as.numeric(Stime), format(Stime, '%d %b'))
points(x$Italy[, c('time', 'deaths')], col = 'red')
matplot(
  toPredict$time,
  exp(do.call(
    cbind,
    mgcv::predict.gam(gamItaly$gam, toPredict, se.fit = TRUE)
  )
  %*% Pmisc::ciMat()),
  col = 'black',
  lty = c(1, 2, 2),
  type = 'l',
  xaxt = 'n',
  xlab = '',
  ylab = 'count',
  ylim = c(0.5, 5000),
  xlim = as.Date(c('2020/2/20', '2020/4/5')),
  log = 'y'
)
axis(1, as.numeric(Stime), format(Stime, '%d %b'))
points(x$Italy[, c('time', 'deaths')], col = 'red')

matplot(
  toPredict$time,
  exp(do.call(
    cbind,
    mgcv::predict.gam(gamHubei$gam, toPredict, se.fit = TRUE)
  ) %*% Pmisc::ciMat()),
  col = 'black',
  lty = c(1, 2, 2),
  type = 'l',
  xaxt = 'n',
  xlab = '',
  ylab = 'count',
  xlim = as.Date(c('2020/1/20', '2020/4/5'))
)
axis(1, as.numeric(Stime), format(Stime, '%d %b'))
points(x$Hubei[, c('time', 'deaths')], col =
         'red')

matplot(
  toPredict$time,
  exp(do.call(
    cbind,
    mgcv::predict.gam(gamHubei$gam, toPredict, se.fit = TRUE)
  ) %*% Pmisc::ciMat()),
  col = 'black',
  lty = c(1, 2, 2),
  type = 'l',
  xaxt = 'n',
  xlab = '',
  ylab = 'count',
  xlim = as.Date(c('2020/1/20', '2020/4/5')),
  log = 'y',
  ylim = c(0.5, 200)
)
axis(1, as.numeric(Stime), format(Stime, '%d %b'))
points(x$Hubei[, c('time', 'deaths')], col = 'red')
```


\pagebreak
## Question 2.1

*Write down the statistical model corresponding to the gamm4 calls above, explaining in words what all of the variables are.*

**Answer:**

The model corresponding to `gamItaly` is 

$$
\begin{aligned}
  Y_{i} ~ | ~ A_{i} &\sim Poisson(\lambda_{i}) \\
  h(\lambda_{i}) = log(\lambda_{i}) 
   & = X_{i} \beta + A_{i} + f(W_{i}; v) + \epsilon_{i} \\
  A_{i} &\sim N(0, \sigma_{A}^{2})
\end{aligned}
$$

Where

- $Y_{i}$ is the response variable. It represents the number of deaths for group $i$ in Italy.
- $\lambda_{i}$ is the mean number of deaths for group $i$.
- $h(\lambda_{i})$ is the log link function.
- $X_{i}$, $W_{i}$ are the covariates.
  - $X_{i}$ contain indicator variable `weekday` the day of the week (7 levels).
  - $W_{i}$ contain numeric variable `timeInt` a numeric representation of date.
- $\beta$ are the parameters.
- $A_{i}$ is the $i$th `timeIid`'s (numeric representation of date) deviation from the population average. In this case, every day has its own random intercept.
- $f(w; v)$ are the smoothing functions of `timeInt`, with smoothness parameter $v$, up to $40$ knots.
- $\epsilon_{i}$ are residuals for group $i$.


The model corresponding to `gamHubei` is 

$$
\begin{aligned}
  Y_{i} ~ | ~ A_{i} &\sim Poisson(\lambda_{i}) \\
  h(\lambda_{i}) = log(\lambda_{i}) 
   & = X_{i} \beta + A_{i} + f(W_{i}; v) + \epsilon_{i} \\
  A_{i} &\sim N(0, \sigma_{A}^{2})
\end{aligned}
$$

Where

- $Y_{i}$ is the response variable. It represents the number of deaths for group $i$ in Hubei.
- $\lambda_{i}$ is the mean number of deaths for group $i$.
- $h(\lambda_{i})$ is the log link function.
- $X_{i}$, $W_{i}$ are the covariates.
  - $X_{i}$ contain indicator variable `weekday` the day of the week (7 levels).
  - $W_{i}$ contain numeric variable `timeInt` a numeric representation of date.
- $\beta$ are the parameters.
- $A_{i}$ is the $i$th `timeIid`'s (string representation of date) deviation from the population average. In this case, every day has its own random intercept.
- $f(w; v)$ are the smoothing functions of `timeInt`, with smoothness parameter $v$, up to $100$ knots.
- $\epsilon_{i}$ are residuals for group $i$.

The difference between the two models are

- $Y_{i}$ corresponds to death cases in different regions: `gamItaly` for Italy, and `gamHubei` for Hubei.
- $f(w; v)$ has different number of knots. `gamItaly`'s smoothing function has up to $40$ knots where as `gamHubei`'s smoothing function has up to $100$ knots.


\pagebreak
## Question 2.2

*Write a paragraph describing, in non-technical terms, what information the data analysis presented here is providing. Write text suitable for a short ‘Research News’ article in a University of Toronto news publication, assuming the audience knows some basic statistics but not much about non-parametric modelling.*

**Answer:**

<!-- The log standard deviation for `timeInt` random effect in Italy is 0.10172. This means that each day explains `r round(exp(0.10172)^2, digits = 4)` of the variance in death cases in Italy. -->

<!-- The log standard deviation for `timeInt` random effect in Hubei is 0.41303. This means that each day explains `r round(exp(0.41303)^2, digits = 4)` of the variance in death cases in Hubei. -->

On a typical Friday in Italy, it is likely to have $exp(1.000) = 1$ death cases. Using a $95\%$ confindence interval ($effect \pm 2 \times se$), we can see that only Monday's confidence interval does not include 0. This means that with $95\%$ confidence, we can say that comparing to Friday, monday is more likely to have higher number of death cases in Italy, where as other days do not have a significant effect on the number of death cases in Italy.

On a typical Friday in Hubei, it is likely to have $exp(-1.493) = 0.2247$ death cases. Using a $95\%$ confindence interval ($effect \pm 2 \times se$), we can see that all confidence intervals include 0. This means that the days of the week do not have a signifancant effect on the number of death cases in Hubei.

According to the prediction graphs in Figure 5, Italy's death cases seems to be increasing in the future, because the predicted lines and its $95\%$ confidence interval both indicate an upward growth. Hubei's death cases seems to be decreasing in the future. However, the $95\%$ confidence interval seems to diverge. This indicates that although we predict Hubei's death cases will decrease, we cannot make this claim with great confidence, and it is possible that Hubei's death cases will increase in the future.

If the COVID19 spread trend for Italy and Hubei are similar, we can say that Italy has not yet reached the peak of death cases, and there might be more in the future. As for Hubei, it seems that it has already reached its peak, but we can not make a confident claim about what will happen in the future.


\pagebreak
## Question 2.3

*Explain, for each of the tests below, whether the test is a valid LR test and give reasons for your decision.*

``` {r lrtests}
gamHubei = gamm4::gamm4(
  deaths ~ weekday + s(timeInt, k = 100),
  random = ~ (1 | timeIid),
  data = x$Hubei,
  family = poisson(link = 'log')
)
Hubei2 = gamm4::gamm4(
  deaths ~ 1 + s(timeInt, k = 100),
  random = ~ (1 | timeIid),
  data = x$Hubei,
  family = poisson(link = 'log'),
  REML = FALSE
)
Hubei3 = mgcv::gam(
  deaths ~ weekday + s(timeInt, k = 100),
  data = x$Hubei,
  family = poisson(link = 'log'),
  method = 'ML'
)
Hubei4 = lme4::glmer(
  deaths ~ weekday + timeInt + (1 | timeIid),
  data = x$Hubei,
  family = poisson(link = 'log')
)

lmtest::lrtest(Hubei2$mer, gamHubei$mer)
nadiv::LRTest(logLik(Hubei2$mer), logLik(gamHubei$mer), boundaryCorrect = TRUE)
lmtest::lrtest(Hubei3, gamHubei$mer)
nadiv::LRTest(logLik(Hubei3), logLik(gamHubei$mer), boundaryCorrect = TRUE)
lmtest::lrtest(Hubei4, gamHubei$mer)
nadiv::LRTest(logLik(Hubei4), logLik(gamHubei$mer), boundaryCorrect = TRUE)
lmtest::lrtest(Hubei2$mer, Hubei3)
nadiv::LRTest(logLik(Hubei2$mer), logLik(Hubei3), boundaryCorrect = TRUE)
```

**Answer:**

- `lmtest::lrtest(Hubei2$mer, gamHubei$mer)` is not a valid LR test because `gamHubei` is fitted with REML instead of ML, and we shouldn't test REML models with likelihood ratio tests. If it was fitted with ML, the test would be valid because `Hubei2` is nested within `gamHubei`. `Hubei2` is the special case when `gamHubei` removes the `weekday` covariate and uses mean instead.

- `nadiv::LRTest(logLik(Hubei2$mer), logLik(gamHubei$mer), boundaryCorrect = TRUE)` is not a valid LR test because `gamHubei` is fitted with REML instead of ML, and we shouldn't test REML models with likelihood ratio tests. Also, although `Hubei2` is nested within `gamHubei`, we are not testing for the random effect. `gamHubei` and `Hubei2` contain the same random effects (smothing on `timeInt` and random effect of `timeIid`). `boundaryCorrect` should only be set to TRUE when we are testing for random effects.

- `lmtest::lrtest(Hubei3, gamHubei$mer)` is not a valid LR test because `gamHubei` is fitted with REML instead of ML, and we shouldn't test REML models with likelihood ratio tests. Also, although `Hubei3` is nested within `gamHubei`, the difference between the two model is the random effect of `timeIid`. To test for the random effect being significant, it is better to use `nadiv::LRTest`.

- `nadiv::LRTest(logLik(Hubei3), logLik(gamHubei$mer), boundaryCorrect = TRUE)` is a not valid LR test because `gamHubei` is fitted with REML instead of ML, and we shouldn't test REML models with likelihood ratio tests. If it was fitted with ML, the test would be valid because `Hubei3` is nested within `gamHubei`. It is equivalent to setting the random effect `timeIid` to $0$ in gamHubei. By setting `boundaryCorrect = TRUE`, we are testing the significance for the random effect of `timeIid`.

- `lmtest::lrtest(Hubei4, gamHubei$mer)` is not a valid LR test because `gamHubei` is fitted with REML instead of ML, and we shouldn't test REML models with likelihood ratio tests. Also, although `Hubei4` is nested within `gamHubei`. It is equivalent to using straight lines as `f(timeInt)` in `gamHubei`. By testing the two models, we will be testing the significance of the smoothing, which is a random effect. To test for the random effect being significant, it is better to use `nadiv::LRTest`.

- `nadiv::LRTest(logLik(Hubei4), logLik(gamHubei$mer), boundaryCorrect = TRUE)` is not a valid LR test because `gamHubei` is fitted with REML instead of ML, and we shouldn't test REML models with likelihood ratio tests. If it was fitted with ML, the test would be valid because `Hubei4` is nested within `gamHubei`. It is equivalent to using straight lines as `f(timeInt)` in `gamHubei`. by setting `boundaryCorrect = TRUE`, we are testing the significance for smoothing on `timeInt`.

- `lmtest::lrtest(Hubei2$mer, Hubei3)` is not a valid LR test because `Hubei2` and `Hubei3` are not nested. `Hubei2` contains a random effect of `timeIid`, which `Hubei3` does not. `Hubei3` has `weekday` as one of its covariates, but `Hubei2` does not. Thus the two models are not nested, and the LR test is inappropriate.

- `nadiv::LRTest(logLik(Hubei2$mer), logLik(Hubei3), boundaryCorrect = TRUE)` is not a valid LR test because `Hubei2` and `Hubei3` are not nested. `Hubei2` contains a random effect of `timeIid`, which `Hubei3` does not. `Hubei3` has `weekday` as one of its covariates, but `Hubei2` does not. Thus the two models are not nested, and the LR test is inappropriate.

<!-- \newpage -->
<!-- # Appendix -->

<!-- ```{r ref.label=knitr::all_labels(), echo = T, eval = F} -->
<!-- ``` -->
